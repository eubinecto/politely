"""
ì–´ë–»ê²Œ ê¸°ì¡´ì˜ spacingì„ ìœ ì§€í•  ìˆ˜ ìˆì„ê¹Œ?
"""
from kiwipiepy import Kiwi
import numpy as np
kiwi = Kiwi()
sent = "ë‚˜ëŠ” ë„ ì‚¬ ë‘í•´"
tokens = kiwi.tokenize(sent)
# starts & lensë¥¼ ... ìˆ˜ì • í›„ì—ë„ ... ê³„ì† ë°”ê¿”ì¤˜ì•¼í•œë‹¤.
# ê·¸ê²Œ ë¬¸ì œë‹¤. ìŒ...?
# ê·¸ë ‡ë‹¤ë©´, ì‚¬ìš©ìì •ì˜ì‚¬ì „ì„ ê³„ì† ì¶”ê°€í•˜ëŠ” ê²ƒì´ í•„ìš”í•  ê²ƒ.
# ì—¬ê¸°ì„œ ê·¸ë¦¬í•  ê²ƒì´ ì•„ë‹ˆë¼.... ã…‡ã…‡
# ì´ê±´ ê·¸ëƒ¥ ì´ë ‡ê²Œ ë‚¨ê¸°ê² ë‹¤.
starts = np.array([token.start for token in tokens] + [0])
lens = np.array([token.len for token in tokens] + [0])
sums = np.array(starts) + np.array(lens)
spacings = (starts[1:] - sums[:-1]) > 0  # if it is greater than 1, than it should be spaced.
chunks = [f"{token.form}ğŸ·{token.tag}" + "\n" if spacing else f"{token.form}ğŸ·{token.tag}"
          for token, spacing in zip(tokens, spacings)]
sent = "ğŸ”—".join(chunks)
print(sent)
new_sent = ""
for chunk in sent.split("\n"):
    print(chunk)
    new_sent += kiwi.join([tuple(token.split("ğŸ·")) for token in chunk.strip("ğŸ”—").split("ğŸ”—")]).replace(" ", "") + " "
